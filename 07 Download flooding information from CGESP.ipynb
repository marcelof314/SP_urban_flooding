{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Bibliotecas",
   "id": "4a765b057a6a80f7"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-06T21:38:42.627831Z",
     "start_time": "2024-10-06T21:38:42.310835Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "from datetime import date, timedelta\n",
    "import time\n",
    "import pandas as pd\n",
    "import re\n",
    "from tqdm.auto import tqdm"
   ],
   "id": "4fd66f987e206852",
   "outputs": [],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-06T21:38:45.725193Z",
     "start_time": "2024-10-06T21:38:45.718357Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Função para determinar se houve alagamento ou não em um determinado dia\n",
    "def houve_alag(soup):\n",
    "    # Texto padrão quando não houve alagamentos\n",
    "    texto = 'Não há registros de alagamentos para essa data.'\n",
    "\n",
    "    # Variável para alagamento. 0, sem alagamento. 1, com alagamento\n",
    "    flag_alag = 0\n",
    "\n",
    "    alag = soup.find_all(string = re.compile('registros'))\n",
    "    \n",
    "    if (alag == []):\n",
    "        flag_alag = 1\n",
    "        return flag_alag\n",
    "    else:\n",
    "        flag_alag = 0\n",
    "        return flag_alag"
   ],
   "id": "dfcb25fde71b945a",
   "outputs": [],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-06T21:39:13.158052Z",
     "start_time": "2024-10-06T21:39:13.148528Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Cria dataframe para receber o conteúdo\n",
    "Campos = ['Data',\n",
    "           'Alagamento',\n",
    "           'Bairro',\n",
    "           'Tipo',\n",
    "           'Horário Inicial',\n",
    "           'Horário Final',\n",
    "           'Endereço',\n",
    "           'Sentido',\n",
    "           'Referência'\n",
    "           ]\n",
    "df = pd.DataFrame(columns=Campos)\n",
    "\n",
    "# Montagem dinâmica das datas a serem varridas:\n",
    "start = date(2013, 1, 1)\n",
    "end = date(2013, 12, 31)\n",
    "\n",
    "# Datas com problemas\n",
    "# 13/01/2019\n",
    "# 15/11/2019\n",
    "# 22/06/2021\n",
    "# 29/10/2022\n",
    "# 12/03/2023\n",
    "# 17/01/2017\n",
    "\n",
    "# Quando a função estiver totalmente funcional\n",
    "# end = date.today()\n",
    "data_pesquisada = start\n",
    "dia = timedelta(days=1)"
   ],
   "id": "904d3a1c3e7a9805",
   "outputs": [],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-06T21:40:29.457483Z",
     "start_time": "2024-10-06T21:39:46.031498Z"
    }
   },
   "cell_type": "code",
   "source": [
    "index= 0\n",
    "\n",
    "# Inicia o preenchimento do dataframe\n",
    "while data_pesquisada < end:\n",
    "    data_formatada = data_pesquisada.strftime('%d')+'%2F'+data_pesquisada.strftime('%m')+'%2F'+data_pesquisada.strftime('%Y')\n",
    "    URL_pesquisada = 'https://www.cgesp.org/v3/alagamentos.jsp?dataBusca='+data_formatada+'&enviaBusca=Buscar'\n",
    "    #print(URL_pesquisada)\n",
    "\n",
    "    # Faz a requisição para a página\n",
    "    try:\n",
    "        response = requests.get(URL_pesquisada)\n",
    "    except requests.exceptions.Timeout:\n",
    "        print('Timeout informado pelo sistema')\n",
    "    except requests.exceptions.TooManyRedirects:\n",
    "        print('Problema na formação da URL. Favor tentar com outra')\n",
    "    except requests.exceptions.RequestException as e:\n",
    "        print('Erro catastrófico')\n",
    "        raise SystemExit(e)\n",
    "\n",
    "    # Analisa o HTML da página com o BeautifulSoup\n",
    "    soup = BeautifulSoup(response.content, 'html.parser')\n",
    "        \n",
    "    if (houve_alag(soup)==0):\n",
    "        print(f\"Em {data_pesquisada} não houve registros de alagamentos.\")\n",
    "        #df.at[index,'Data'] =  data_pesquisada\n",
    "        #df.at[index,'Alagamento'] = 0\n",
    "        #df.at[index,'Bairro'] = 0\n",
    "        #df.at[index,'Tipo'] = 0\n",
    "        #df.at[index,'Horário Inicial'] = 0\n",
    "        #df.at[index,'Horário Final'] = 0\n",
    "        #df.at[index,'Endereço'] = 0\n",
    "        #df.at[index,'Sentido'] = 0\n",
    "        #df.at[index,'Referência'] = 0\n",
    "        #index = index +1 \n",
    "    else:\n",
    "        index_linhas = 0\n",
    "        for pontos in soup.find_all('td', {'class':'total-pts arial-bairros-alag'}):\n",
    "            texto = pontos.string\n",
    "            no_alag = int(texto[0:texto.find('pt')-1])\n",
    "            print(f'Data: {data_pesquisada}, No. alagamentos: {no_alag}')\n",
    "\n",
    "            linhas = soup.find_all('div',{'class':'ponto-de-alagamento'})\n",
    "            \n",
    "\n",
    "            # Vamos iterar sobre a quantidade de pontos de alagamento\n",
    "            for pt_alag in range(no_alag):\n",
    "            \n",
    "                df.at[index,'Data'] =  data_pesquisada\n",
    "                df.at[index,'Alagamento'] = 1\n",
    "\n",
    "                pai = pontos.parent\n",
    "            \n",
    "                df.at[index,'Bairro'] = pai.find('td',{'class':'bairro arial-bairros-alag linha-pontilhada'}).text.strip()\n",
    "                df.at[index,'Tipo'] = linhas[index_linhas].find('li')['title']\n",
    "            \n",
    "                #'Horário Inicial',\n",
    "                texto1 = linhas[index_linhas].find('li', {'class':'arial-descr-alag col-local'}).text\n",
    "                horas =re.findall('(?:(\\d\\d?):)?([0-5][0-9])',texto1)\n",
    "                df.at[index,'Horário Inicial'] = str(horas[0][0])+':'+str(horas[0][1])\n",
    "                \n",
    "                # Tenta capturar o 'Horário Final', se não conseguir, preenche com \"N/A\"\n",
    "                try:\n",
    "                    df.at[index,'Horário Final'] = str(horas[1][0])+':'+str(horas[1][1])\n",
    "                    # Usa o horário final para encontrar o início do endereço\n",
    "                    pos_endereco = texto1.find(horas[1][1]) + 2\n",
    "                except IndexError:\n",
    "                    df.at[index,'Horário Final'] = \"N/A\"  \n",
    "                    # Se não houver horário final, encontra o endereço baseado no horário inicial\n",
    "                    pos_endereco = texto1.find(horas[0][1]) + 2\n",
    "    \n",
    "                # Extrai o endereço usando a posição determinada anteriormente\n",
    "                df.at[index, 'Endereço'] = texto1[pos_endereco:].strip()\n",
    "\n",
    "                #'Sentido',\n",
    "                texto2 = linhas[index_linhas].find_all('li', {'class':'arial-descr-alag'})\n",
    "                info = texto2[1].get_text()\n",
    "                df.at[index,'Sentido'] = info[8:info.find('Ref')]\n",
    "\n",
    "                #'Referência'\n",
    "                df.at[index,'Referência'] = info[info.find('Ref')+11:len(info)]\n",
    "            \n",
    "                index = index +1 \n",
    "                index_linhas = index_linhas +1\n",
    "    data_pesquisada = data_pesquisada + dia\n",
    "    time.sleep(2)"
   ],
   "id": "e77831a13efea53a",
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[4], line 85\u001B[0m\n\u001B[1;32m     83\u001B[0m             index_linhas \u001B[38;5;241m=\u001B[39m index_linhas \u001B[38;5;241m+\u001B[39m\u001B[38;5;241m1\u001B[39m\n\u001B[1;32m     84\u001B[0m data_pesquisada \u001B[38;5;241m=\u001B[39m data_pesquisada \u001B[38;5;241m+\u001B[39m dia\n\u001B[0;32m---> 85\u001B[0m \u001B[43mtime\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43msleep\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m2\u001B[39;49m\u001B[43m)\u001B[49m\n",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-06T21:40:32.364461Z",
     "start_time": "2024-10-06T21:40:32.354934Z"
    }
   },
   "cell_type": "code",
   "source": "URL_pesquisada",
   "id": "d6ffa6d263a83b8f",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'https://www.cgesp.org/v3/alagamentos.jsp?dataBusca=21%2F01%2F2013&enviaBusca=Buscar'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 5
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "df.to_csv('Alagamentos_SP_2013.csv', encoding='utf-8-sig')",
   "id": "3ff6bbb687a286eb"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
